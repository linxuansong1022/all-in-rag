import os
import asyncio
from dotenv import load_dotenv, find_dotenv
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings
from llama_index.core.node_parser import SentenceWindowNodeParser, SentenceSplitter
from llama_index.llms.google_genai import GoogleGenAI
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from llama_index.core.postprocessor import MetadataReplacementPostProcessor
from llama_index.core.evaluation import (
    FaithfulnessEvaluator,
    RelevancyEvaluator,
    BatchEvalRunner,
)
from llama_index.core.evaluation import DatasetGenerator, QueryResponseDataset

"""
=== RAG æ•ˆæœè¯„ä¼°æ¼”ç¤º (RAG Evaluation) ===
... (comments omitted for brevity) ...
"""

# åŠ è½½ç¯å¢ƒå˜é‡
# é¦–å…ˆå°è¯•åŠ è½½å½“å‰ç›®å½•çš„ .envï¼Œå¦‚æœæ‰¾ä¸åˆ°åˆ™è‡ªåŠ¨å‘ä¸Šæœç´¢
load_dotenv() 

# å¦‚æœä¸Šé¢çš„æ²¡åŠ è½½åˆ° Keyï¼Œæˆ‘ä»¬å†å¼ºåˆ¶å°è¯•åŠ è½½ä¸€æ¬¡æ ¹ç›®å½•çš„ï¼ˆåŒé‡ä¿é™©ï¼‰
if not os.getenv("GOOGLE_API_KEY"):
    load_dotenv("../../.env")

# æ£€æŸ¥ API Key æ˜¯å¦å­˜åœ¨
api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    print("âŒ é”™è¯¯: æœªæ‰¾åˆ° GOOGLE_API_KEY ç¯å¢ƒå˜é‡ã€‚")
    print("è¯·ç¡®ä¿ .env æ–‡ä»¶å­˜åœ¨äºå½“å‰ç›®å½• (code/C6) æˆ–é¡¹ç›®æ ¹ç›®å½•ã€‚")
    print("ä¸”æ–‡ä»¶ä¸­åŒ…å«: GOOGLE_API_KEY=ä½ çš„Key")
    exit(1)
else:
    print(f"âœ… å·²æˆåŠŸåŠ è½½ GOOGLE_API_KEY (å‰5ä½: {api_key[:5]}...)")

# ==========================================
# 0. å…¨å±€é…ç½® (Global Settings)
# ==========================================
# é…ç½® LLM ä¸º Gemini
Settings.llm = GoogleGenAI(
    model="models/gemini-2.0-flash", 
    api_key=api_key,
    temperature=0
)
# é…ç½® Embedding æ¨¡å‹
Settings.embed_model = HuggingFaceEmbedding(model_name="BAAI/bge-small-en-v1.5")


async def main():
    # ==========================================
    # 1. å‡†å¤‡æ•°æ® (Prepare Data)
    # ==========================================
    print("æ­£åœ¨åŠ è½½æ–‡æ¡£...")
    try:
        reader = SimpleDirectoryReader(input_files=["../../data/C3/pdf/IPCC_AR6_WGII_Chapter03.pdf"])
        documents = reader.load_data()
    except Exception as e:
        print(f"æ–‡æ¡£åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥è·¯å¾„: {e}")
        return

    # ==========================================
    # 2. ç”Ÿæˆè€ƒé¢˜ (Generate Evaluation Dataset)
    # ==========================================
    # å¦‚æœæœ¬åœ°å·²ç»æœ‰ç”Ÿæˆçš„è€ƒé¢˜é›†ï¼Œå°±ç›´æ¥åŠ è½½ï¼Œå¦åˆ™ç°åœºç”Ÿæˆ
    dataset_path = "./c6_response_eval_dataset.json"
    
    if os.path.exists(dataset_path):
        print("åŠ è½½ç°æœ‰çš„è¯„ä¼°æ•°æ®é›†...")
        response_eval_dataset = QueryResponseDataset.from_json(dataset_path)
    else:
        print("æ­£åœ¨ç”Ÿæˆè¯„ä¼°æ•°æ®é›† (è¿™å¯èƒ½éœ€è¦ä¸€åˆ†é’Ÿ)...")
        # ä¸ºäº†æ¼”ç¤ºå¿«ä¸€ç‚¹ï¼Œæˆ‘ä»¬åªå–å‰ 4 é¡µæ–‡æ¡£
        dataset_generator = DatasetGenerator.from_documents(
            documents[:4], 
            llm=Settings.llm
        )
        # ç”Ÿæˆ 10 ä¸ªé—®é¢˜
        response_eval_dataset = await dataset_generator.agenerate_dataset_from_nodes(num=10)
        response_eval_dataset.save_json(dataset_path)
        print("æ•°æ®é›†ç”Ÿæˆå®Œæ¯•å¹¶ä¿å­˜ã€‚")

    queries = response_eval_dataset.queries
    print(f"å‡†å¤‡äº† {len(queries)} ä¸ªæµ‹è¯•é—®é¢˜ã€‚")

    # ==========================================
    # 3. å‡†å¤‡ä¸¤ä¸ªè€ƒç”Ÿ (Build 2 Query Engines)
    # ==========================================
    
    # --- è€ƒç”Ÿ Aï¼šå¥å­çª—å£æ£€ç´¢ (Sentence Window Retrieval) ---
    # è¿™ç§ç­–ç•¥ä¼šåˆ‡åˆ†å¾—å¾ˆç»†ï¼Œä½†åœ¨æ£€ç´¢æ—¶ä¼šæŠŠå‘¨å›´çš„å¥å­å¸¦å‡ºæ¥ï¼Œé€šå¸¸æ•ˆæœæ›´å¥½
    print("åˆå§‹åŒ–è€ƒç”Ÿ A (å¥å­çª—å£æ£€ç´¢)...")
    sentence_parser = SentenceWindowNodeParser.from_defaults(
        window_size=5,
        window_metadata_key="window",
        original_text_metadata_key="original_text",
    )
    sentence_nodes = sentence_parser.get_nodes_from_documents(documents)
    sentence_index = VectorStoreIndex(sentence_nodes)

    sentence_query_engine = sentence_index.as_query_engine(
        similarity_top_k=2,
        node_postprocessors=[
            MetadataReplacementPostProcessor(target_metadata_key="window")
        ],
    )

    # --- è€ƒç”Ÿ Bï¼šåŸºç¡€æ£€ç´¢ (Base Retrieval) ---
    # è¿™ç§æ˜¯æ™®é€šçš„åˆ‡åˆ†ç­–ç•¥ï¼Œæ¯å— 512 ä¸ªå­—
    print("åˆå§‹åŒ–è€ƒç”Ÿ B (å¸¸è§„åˆ†å—æ£€ç´¢)...")
    base_parser = SentenceSplitter(chunk_size=512)
    base_nodes = base_parser.get_nodes_from_documents(documents)
    base_index = VectorStoreIndex(base_nodes)
    
    base_query_engine = base_index.as_query_engine(similarity_top_k=2)

    # ==========================================
    # 4. è£åˆ¤å…¥åœº (Initialize Evaluators)
    # ==========================================
    faithfulness_evaluator = FaithfulnessEvaluator(llm=Settings.llm)
    relevancy_evaluator = RelevancyEvaluator(llm=Settings.llm)
    
    evaluators = {
        "faithfulness": faithfulness_evaluator, 
        "relevancy": relevancy_evaluator
    }

    # ==========================================
    # 5. è€ƒè¯•å¼€å§‹ (Run Evaluation)
    # ==========================================
    print("\n=== è€ƒç”Ÿ A (å¥å­çª—å£) å¼€å§‹ç­”é¢˜å¹¶æ¥å—è¯„ä¼° ===")
    runner = BatchEvalRunner(evaluators, workers=2, show_progress=True)
    sentence_results = await runner.aevaluate_queries(
        queries=queries, query_engine=sentence_query_engine
    )

    print("\n=== è€ƒç”Ÿ B (å¸¸è§„åˆ†å—) å¼€å§‹ç­”é¢˜å¹¶æ¥å—è¯„ä¼° ===")
    base_results = await runner.aevaluate_queries(
        queries=queries, query_engine=base_query_engine
    )

    # ==========================================
    # 6. å…¬å¸ƒæˆç»© (Print Results)
    # ==========================================
    def print_eval_details(runner_name, eval_results, queries_dict):
        """æ‰“å°æ‰£åˆ†é¡¹çš„è¯¦ç»†ç†ç”±"""
        print(f"\n--- {runner_name} æ‰£åˆ†é¡¹è¯¦ç»†åˆ†æ ---")
        # eval_results æ˜¯ä¸€ä¸ªå­—å…¸: {"faithfulness": [results], "relevancy": [results]}
        # å¯¹åº”çš„æ˜¯ queries åˆ—è¡¨ä¸­çš„é¡ºåº
        # å› ä¸ºæˆ‘ä»¬æ— æ³•ç›´æ¥ä» EvaluatorResponse è·å–åŸå§‹é—®é¢˜ï¼Œæ‰€ä»¥éœ€è¦éå†
        for metric, results in eval_results.items():
            for i, res in enumerate(results):
                if res.score < 1.0:
                    # å°è¯•ä» queries åˆ—è¡¨ä¸­è·å–å¯¹åº”çš„é—®é¢˜
                    query_list = list(queries_dict.values())
                    query_text = query_list[i] if i < len(query_list) else "æœªçŸ¥é—®é¢˜"
                    print(f"\nâŒ [{metric.upper()}] æ‰£åˆ†é¢˜ç›®: {query_text}")
                    print(f"ğŸ’¡ æ‰£åˆ†ç†ç”±: {res.feedback}")
                    # print(f"ğŸ“ å‚è€ƒè¯æ®: {res.contexts}") # å¦‚æœéœ€è¦æŸ¥çœ‹æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡å¯ä»¥å¼€å¯

    def get_score(results, metric_name):
        """è®¡ç®—å¹³å‡åˆ†"""
        scores = results[metric_name]
        total_score = sum(result.score for result in scores)
        return total_score / len(scores)

    print("\n" + "="*40)
    print("ğŸ† æœ€ç»ˆæˆç»©å•")
    print("="*40)

    # è€ƒç”Ÿ A æˆç»©
    s_faith = get_score(sentence_results, "faithfulness")
    s_rel = get_score(sentence_results, "relevancy")
    print(f"è€ƒç”Ÿ A (å¥å­çª—å£):")
    print(f"  - å¿ å®åº¦ (ä¸çç¼–): {s_faith:.1%}")
    print(f"  - ç›¸å…³æ€§ (ä¸è·‘é¢˜): {s_rel:.1%}")
    if s_faith < 1.0 or s_rel < 1.0:
        print_eval_details("è€ƒç”Ÿ A", sentence_results, queries)

    # è€ƒç”Ÿ B æˆç»©
    b_faith = get_score(base_results, "faithfulness")
    b_rel = get_score(base_results, "relevancy")
    print(f"\nè€ƒç”Ÿ B (å¸¸è§„åˆ†å—):")
    print(f"  - å¿ å®åº¦ (ä¸çç¼–): {b_faith:.1%}")
    print(f"  - ç›¸å…³æ€§ (ä¸è·‘é¢˜): {b_rel:.1%}")
    if b_faith < 1.0 or b_rel < 1.0:
        print_eval_details("è€ƒç”Ÿ B", base_results, queries)

    # æ€»ç»“
    print("\n[æ€»ç»“]:")
    if s_faith >= b_faith and s_rel >= b_rel:
        print("âœ… å¥å­çª—å£æ£€ç´¢ (è€ƒç”ŸA) å®Œèƒœï¼")
    elif s_faith < b_faith and s_rel < b_rel:
        print("âŒ å¸¸è§„æ£€ç´¢ (è€ƒç”ŸB) ç«Ÿç„¶èµ¢äº†ï¼Ÿå¯èƒ½æ˜¯æ–‡æ¡£å¤ªç®€å•äº†ã€‚")
    else:
        print("âš–ï¸ ä¸¤è€…äº’æœ‰èƒœè´Ÿã€‚")


if __name__ == "__main__":
    asyncio.run(main())

